{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f25489ee",
   "metadata": {},
   "source": [
    "### Query Enhancement â€“ Query Expansion Techniques\n",
    "\n",
    "In a RAG pipeline, the quality of the query sent to the retriever determines how good the retrieved context is â€” and therefore, how accurate the LLMâ€™s final answer will be.\n",
    "\n",
    "Thatâ€™s where Query Expansion / Enhancement comes in.\n",
    "\n",
    "#### ðŸŽ¯ What is Query Enhancement?\n",
    "Query enhancement refers to techniques used to improve or reformulate the user query to retrieve better, more relevant documents from the knowledge base.\n",
    "It is especially useful when:\n",
    "\n",
    "- The original query is short, ambiguous, or under-specified\n",
    "- You want to broaden the scope to catch synonyms, related phrases, or spelling variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9de389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.2.4)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-text-splitters in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.2.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (0.4.59)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.0.44)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (3.13.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-huggingface) (0.36.0)\n",
      "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-huggingface) (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.12.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-core langchain-community langchain-text-splitters langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ff6ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "752d3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## step1 : Load and split the dataset\n",
    "loader = TextLoader(\"langchain_crewai_dataset.txt\")\n",
    "raw_docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(raw_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791ba3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v1)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v1)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v2)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v2)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v3)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v3)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v4)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v4)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v5)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v5)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v6)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v6)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v7)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v7)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v8)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v8)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v9)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v9)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is an open-source framework designed for developing applications powered by large language models (LLMs). It simplifies the process of building, managing, and scaling complex chains of thought by abstracting prompt management, retrieval, memory, and agent orchestration. Developers can use'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and agent orchestration. Developers can use LangChain to create end-to-end pipelines that connect LLMs with tools, APIs, vector databases, and other knowledge sources. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='At the heart of LangChain lies the concept of chains, which are sequences of calls to LLMs and other tools. Chains can be simple, such as a single prompt fed to an LLM, or complex, involving multiple conditionally executed steps. LangChain makes it easy to compose and reuse chains using standard'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='easy to compose and reuse chains using standard patterns like Stuff, Map-Reduce, and Refine. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain integrates seamlessly with vector databases like FAISS, Chroma, Pinecone, and Weaviate, enabling semantic search within large document corpora. This capability is especially important in Retrieval-Augmented Generation (RAG), where external knowledge is fetched and injected into the LLM'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='knowledge is fetched and injected into the LLM prompt to enhance accuracy and reduce hallucination. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain also supports hybrid retrieval, which combines keyword-based (sparse) retrieval methods like BM25 with embedding-based (dense) retrieval. This ensures better recall by catching both exact term matches and semantically similar content. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='One of the standout features of LangChain is its support for agents. Agents use LLMs to reason about which tool to call, what input to provide, and how to process the output. LangChain agents can execute multi-step tasks, integrating with tools like web search, calculators, code execution'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='like web search, calculators, code execution environments, and custom APIs. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain agents operate using a planner-executor model, where the agent plans out a sequence of tool invocations to achieve a goal. This can include dynamic decision-making, branching logic, and context-aware memory use across steps. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain offers memory modules like ConversationBufferMemory and ConversationSummaryMemory. These allow the LLM to maintain awareness of previous conversation turns or summarize long interactions to fit within token limits. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Prompt engineering is central to LangChainÃ¢â‚¬â„¢s design. It provides templating capabilities, input variables, formatting options, and prompt chaining. Developers can reuse prompt templates across different chains and even nest them. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain is compatible with multiple LLM providers including OpenAI, Anthropic, Cohere, Hugging Face, and more. This flexibility ensures that developers can switch between models without rewriting core logic. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='LangChain workflows are modular and composable. Components like retrievers, memories, agents, and chains can be easily combined and reused. This makes it ideal for building scalable, maintainable LLM applications. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is a multi-agent orchestration framework designed to build collaborative LLM-powered agents. It enables developers to structure agents into organized crews that work together to complete tasks by dividing responsibilities, sharing context, and dynamically communicating with one another.'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='and dynamically communicating with one another. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI builds on the concept of autonomous agents but enhances it by allowing agents to form structured workflows. Each agent in a crew has a defined role, such as researcher, planner, or executor, and operates semi-independently within a collaborative context. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI agents are defined with a purpose, a goal, and a set of tools they can use. The framework ensures that each agent stays on task and contributes meaningfully to the overall crew objective. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content=\"One of CrewAI's core innovations is the use of agent context-sharing, where agents pass intermediate data to one another in a structured manner. This leads to emergent behaviors like delegation, consultation, and review among agents. (v10)\"),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is especially useful in multi-step workflows like market research, legal document analysis, product development, and coding assistants, where complex tasks benefit from specialization and collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='The framework supports full traceability of agent decisions and interactions, making debugging and transparency easier compared to standalone agent setups. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI is compatible with LangChain agents and tools, allowing hybrid systems where LangChain handles retrieval and tool wrapping, while CrewAI manages role-based collaboration. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='Developers can define a crew using a YAML or JSON-like configuration, specifying agent roles, goals, memory, and tools. CrewAI then orchestrates the agent loop and handles turn-taking and decision-making autonomously. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='CrewAI supports multiple LLM backends and includes support for streaming, parallel execution, and asynchronous tool invocation, making it suitable for both fast-prototyping and production-ready systems. (v10)'),\n",
       " Document(metadata={'source': 'langchain_crewai_dataset.txt'}, page_content='By enabling structured agent collaboration, CrewAI empowers teams to build intelligent systems that scale both horizontally (more agents) and vertically (more reasoning depth). (v10)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f001ff8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001EFB47EEA80>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### step 2: Vector Store\n",
    "embedding_model=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore=FAISS.from_documents(chunks,embedding_model)\n",
    "\n",
    "## step 3:MMR Retriever\n",
    "retriever=vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":5})\n",
    "retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e8f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001EFB476DD00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EFB5F78170>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## step 4 : LLM and Prompt\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a72917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116e2cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='Generate 3 alternative expanded search queries\\nfor the input below. Each query should emphasize different\\ntechnical aspects.\\n\\nQuery: \"{query}\"\\n\\nReturn each on a new line.'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001EFB476DD00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001EFB5F78170>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Generate 3 alternative expanded search queries\n",
    "for the input below. Each query should emphasize different\n",
    "technical aspects.\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Return each on a new line.\"\"\"\n",
    ")\n",
    "\n",
    "query_expansion_chain = query_expansion_prompt | llm | StrOutputParser()\n",
    "query_expansion_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_expansion_chain.invoke({\"query\":\"Langchain memory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG answering prompt\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm=llm,prompt=answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Full RAG pipeline with query expansion\n",
    "rag_pipeline = (\n",
    "    RunnableMap({\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"context\": lambda x: retriever.invoke(query_expansion_chain.invoke({\"query\": x[\"input\"]}))\n",
    "    })\n",
    "    | document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebe80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hereâ€™s an expanded search query that adds synonyms, technical terms and useful context for better recall of LangChainâ€™s memory features:\n",
      "\n",
      "â€œLangChain memory supportâ€ OR â€œLangChain memory typesâ€ OR â€œLangChain memory modulesâ€ OR â€œLangChain memory classesâ€  \n",
      "AND (â€œConversationBufferMemoryâ€ OR â€œConversationSummaryMemoryâ€ OR â€œCombinedMemoryâ€ OR â€œDynamicMemoryâ€ OR â€œConversationTokenBufferMemoryâ€)  \n",
      "OR (â€œshort-term memoryâ€ OR â€œlong-term memoryâ€ OR â€œephemeral memoryâ€ OR â€œsession stateâ€ OR â€œcontext windowâ€)  \n",
      "OR (â€œpersistent memoryâ€ OR â€œstateful memory storeâ€ OR â€œmemory retrieverâ€)  \n",
      "OR (â€œvector store memoryâ€ OR â€œembedding storeâ€ OR â€œsemantic memoryâ€ OR â€œRAGâ€)  \n",
      "OR (â€œChromaâ€ OR â€œFAISSâ€ OR â€œPineconeâ€ OR â€œWeaviateâ€ OR â€œRedisâ€ OR â€œSQLiteâ€ OR â€œPostgreSQLâ€ OR â€œMongoDBâ€)  \n",
      "OR (â€œmemory APIâ€ OR â€œmemory variableâ€ OR â€œmemory backendâ€ OR â€œcacheâ€ OR â€œin-memoryâ€ OR â€œfile-basedâ€)  \n",
      "AND (â€œLangChain Pythonâ€ OR â€œLLMChainâ€ OR â€œchatbot context managementâ€ OR â€œagent state managementâ€)\n",
      "âœ… Answer:\n",
      " LangChain currently ships with two built-in memory classes:  \n",
      "1. ConversationBufferMemory â€“ keeps the raw chat history inâ€memory.  \n",
      "2. ConversationSummaryMemory â€“ maintains a running summary of past turns to stay within token limits.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run query\n",
    "query = {\"input\": \"What types of memory does LangChain support?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"âœ… Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd86621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded query:\n",
      "\n",
      "(\"CrewAI agents\" OR \"Crew AI agents\" OR \"CrewAI bots\" OR \"Crew AI assistants\" OR \"autonomous crew agents\" OR \"AI-driven crew management assistants\" OR \"virtual crew members\" OR \"digital crew agents\")  \n",
      "AND  \n",
      "(\"crew scheduling\" OR \"workforce management\" OR \"staff rostering\" OR \"resource allocation\" OR \"employee roster optimization\")  \n",
      "AND  \n",
      "(\"multi-agent system\" OR \"autonomous agents\" OR \"distributed AI\" OR \"agent-based modeling\")  \n",
      "AND  \n",
      "(\"machine learning\" OR \"reinforcement learning\" OR \"predictive analytics\" OR \"optimization algorithms\" OR \"real-time planning\")  \n",
      "AND  \n",
      "(\"airline\" OR \"maritime\" OR \"hospitality\" OR \"logistics\" OR \"field service\")\n",
      "âœ… Answer:\n",
      " CrewAI agents are semi-autonomous, role-specialized AI â€œworkersâ€ that team up in a predefined workflow to tackle complex, multi-step tasks.  Key points:  \n",
      "1. Defined Roles  \n",
      "   â€¢ Researcher â€“ gathers data and insights  \n",
      "   â€¢ Planner â€“ lays out strategy, timelines, and dependencies  \n",
      "   â€¢ Executor â€“ carries out concrete actions (e.g. drafting text, writing code, running analyses)  \n",
      "   â€¢ Reviewer/Validator â€“ checks quality and flags issues  \n",
      "\n",
      "2. Structured Collaboration  \n",
      "   â€¢ Unlike solitary autonomous agents, CrewAIâ€™s agents pass work products and feedback along a chain of responsibility, ensuring each subtask is handled by the most appropriate specialist.  \n",
      "   â€¢ Communication channels and hand-off protocols are built into the system, so progress and context flow smoothly from one agent to the next.  \n",
      "\n",
      "3. Use Cases  \n",
      "   â€¢ Market Research â€“ one agent mines data, another synthesizes findings, a third writes the report.  \n",
      "   â€¢ Legal Document Analysis â€“ a specialist agent extracts clauses, another summarizes risks, a reviewer validates accuracy.  \n",
      "   â€¢ Product Development â€“ ideation, prototyping, testing, documentation handled by distinct agents.  \n",
      "   â€¢ Coding Assistance â€“ design, implementation, debugging, and code review split across agents.  \n",
      "\n",
      "By combining specialization (each agent does what it does best) with a clear, collaborative workflow, CrewAI agents can handle end-to-end, multi-stage tasks more efficiently and reliably than lone AI assistants.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Run query\n",
    "query = {\"input\": \"CrewAI agents?\"}\n",
    "print(query_expansion_chain.invoke({\"query\":query}))\n",
    "response = rag_pipeline.invoke(query)\n",
    "print(\"âœ… Answer:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03d32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
